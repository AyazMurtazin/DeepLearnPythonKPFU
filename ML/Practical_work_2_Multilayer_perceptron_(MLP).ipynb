{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AyazMurtazin/DeepLearnPythonKPFU/blob/main/ML/Practical_work_2_Multilayer_perceptron_(MLP).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Практическая работа №2. Многослойный перцептрон (MLP)**\n",
        "\n"
      ],
      "metadata": {
        "id": "ogAJlPVfkp5H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Задача 1: Подготовка данных**\n"
      ],
      "metadata": {
        "id": "HzRF36KkksPe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.ensemble import IsolationForest\n",
        "\n",
        "# Загрузка данных\n",
        "data = fetch_california_housing()\n",
        "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "df['target'] = data.target\n",
        "\n",
        "# Проверка на пропущенные значения\n",
        "print(\"Пропущенные значения:\\n\", df.isnull().sum())\n",
        "\n",
        "# Обнаружение выбросов методом Isolation Forest\n",
        "iso = IsolationForest(contamination=0.01, random_state=42)\n",
        "outliers = iso.fit_predict(df.drop(columns='target'))\n",
        "df_cleaned = df[outliers == 1]\n",
        "\n",
        "# Масштабирование числовых признаков\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(df_cleaned.drop(columns='target'))\n",
        "y = df_cleaned['target'].values\n",
        "\n",
        "# Разделение данных\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0TXCAEGQkunV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Задача 2: Feature Engineering**\n"
      ],
      "metadata": {
        "id": "D70BsCzukxZ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "# Генерация полиномиальных признаков (степень 2)\n",
        "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
        "X_train_poly = poly.fit_transform(X_train)\n",
        "X_test_poly = poly.transform(X_test)\n",
        "\n",
        "# Проверка на мультиколлинеарность через корреляцию\n",
        "corr_matrix = pd.DataFrame(X_train_poly).corr()\n",
        "sns.heatmap(corr_matrix, cmap='coolwarm')\n",
        "plt.title(\"Корреляционная матрица новых признаков\")\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NhHT6JTik0zg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Задача 3: Анализ корреляции и проверка гипотез**\n"
      ],
      "metadata": {
        "id": "GjXtWLu4k2ey"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from scipy.stats import ttest_ind, shapiro\n",
        "\n",
        "# Корреляционная матрица\n",
        "sns.heatmap(df_cleaned.corr(), annot=True, cmap='coolwarm')\n",
        "plt.title(\"Корреляция признаков\")\n",
        "plt.show()\n",
        "\n",
        "# Проверка нормальности (Шапиро-Уилка) для одного признака\n",
        "stat, p = shapiro(df_cleaned['AveRooms'])\n",
        "print(f\"Шапиро-Уилк для 'AveRooms': p-value = {p:.4f}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Sgb2V3TAk46x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Задача 4: Подготовка данных для MLP**\n"
      ],
      "metadata": {
        "id": "Pq5FyMXvk8YK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Повторное масштабирование с учетом многослойного перцептрона (если нужно)\n",
        "# В нашем случае уже применён StandardScaler на табличные данные\n",
        "X_mlp_train, X_mlp_test = X_train_poly, X_test_poly  # Используем расширенные признаки\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "WywYuNyRk9d4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Задача 5: Построение и анализ архитектуры MLP**\n"
      ],
      "metadata": {
        "id": "UE5x9yA9k-hk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import MeanSquaredError\n",
        "import time\n",
        "\n",
        "def build_model(layers):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(128, activation='relu', input_shape=(X_mlp_train.shape[1],)))\n",
        "    for _ in range(layers - 2):\n",
        "        model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dense(1))  # выходной слой для регрессии\n",
        "    model.compile(optimizer=Adam(), loss='mse', metrics=['mae'])\n",
        "    return model\n",
        "\n",
        "# Сравнение 3 vs 5 слоёв\n",
        "for depth in [3, 5]:\n",
        "    model = build_model(depth)\n",
        "    start = time.time()\n",
        "    history = model.fit(X_mlp_train, y_train, validation_split=0.2, epochs=20, verbose=0)\n",
        "    duration = time.time() - start\n",
        "    print(f\"Model with {depth} layers: MAE = {min(history.history['val_mae']):.4f}, Time = {duration:.2f}s\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "a69hZr66k_oa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Задача 6: Методы оптимизации и анализ градиентов**\n"
      ],
      "metadata": {
        "id": "Cg2C5YoWlA_Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Пример градиента для MSE\n",
        "x = torch.tensor([1.0, 2.0], requires_grad=True)\n",
        "y_true = torch.tensor([1.5])\n",
        "model = nn.Linear(2, 1)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "y_pred = model(x)\n",
        "loss = criterion(y_pred, y_true)\n",
        "loss.backward()\n",
        "print(f\"Градиенты: {x.grad}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "JD8J1QtBlUGY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Задача 7: Регуляризация и борьба с переобучением**\n"
      ],
      "metadata": {
        "id": "wU8PCFEllCSS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.layers import Dropout, BatchNormalization\n",
        "\n",
        "model_reg = Sequential([\n",
        "    Dense(64, activation='relu', kernel_regularizer=l2(0.01), input_shape=(X_mlp_train.shape[1],)),\n",
        "    Dropout(0.3),\n",
        "    BatchNormalization(),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(1)\n",
        "])\n",
        "model_reg.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "model_reg.fit(X_mlp_train, y_train, epochs=20, validation_split=0.2, verbose=0)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Uk_l9cf9lFPt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Задача 8: Оценка качества и интерпретация**\n"
      ],
      "metadata": {
        "id": "qPdiAAcolHf-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import shap\n",
        "\n",
        "# Оценка модели\n",
        "y_pred = model_reg.predict(X_mlp_test)\n",
        "print(\"MAE:\", mean_absolute_error(y_test, y_pred))\n",
        "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
        "print(\"R2:\", r2_score(y_test, y_pred))\n",
        "\n",
        "# Интерпретация SHAP\n",
        "explainer = shap.Explainer(model_reg, X_mlp_train)\n",
        "shap_values = explainer(X_mlp_test[:100])\n",
        "shap.plots.beeswarm(shap_values)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "IkzCewg4lIew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Задача 9: Продвинутые техники и оптимизация**\n"
      ],
      "metadata": {
        "id": "HBLfbcMclJq4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q \"optuna>=3.0.0\""
      ],
      "metadata": {
        "id": "-e573bi-w5Dh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "\n",
        "def objective(trial):\n",
        "    n_layers = trial.suggest_int('hidden_layers', 2, 4)\n",
        "    units = trial.suggest_categorical('units', [32, 64, 128])\n",
        "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Dense(units, activation='relu', input_shape=(X_mlp_train.shape[1],)))\n",
        "    for _ in range(n_layers - 1):\n",
        "        model.add(Dense(units, activation='relu'))\n",
        "        model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(1))\n",
        "\n",
        "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "    model.fit(X_mlp_train, y_train, validation_split=0.2, epochs=10, verbose=0)\n",
        "    loss, mae = model.evaluate(X_mlp_test, y_test, verbose=0)\n",
        "    return mae\n",
        "\n",
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=10)\n",
        "print(\"Лучшие параметры:\", study.best_params)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "XSNBK9u5lKbU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Задача 10: Анализ результатов и выбор модели**\n"
      ],
      "metadata": {
        "id": "5SOrqFuTlMDV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Обучение и предсказания для модели с 3 скрытыми слоями\n",
        "model_3 = build_model(3)\n",
        "model_3.fit(X_mlp_train, y_train, epochs=10, verbose=0)\n",
        "y_pred_3 = model_3.predict(X_mlp_test)\n",
        "\n",
        "# Обучение и предсказания для модели с 5 скрытыми слоями\n",
        "model_5 = build_model(5)\n",
        "model_5.fit(X_mlp_train, y_train, epochs=10, verbose=0)\n",
        "y_pred_5 = model_5.predict(X_mlp_test)\n",
        "\n",
        "# Предсказания модели с регуляризацией (предположим, она обучена заранее как model_reg)\n",
        "y_pred_reg = model_reg.predict(X_mlp_test)\n",
        "\n",
        "# Оценка качества моделей\n",
        "mae_3 = mean_absolute_error(y_test, y_pred_3)\n",
        "mse_3 = mean_squared_error(y_test, y_pred_3)\n",
        "\n",
        "mae_5 = mean_absolute_error(y_test, y_pred_5)\n",
        "mse_5 = mean_squared_error(y_test, y_pred_5)\n",
        "\n",
        "mae_reg = mean_absolute_error(y_test, y_pred_reg)\n",
        "mse_reg = mean_squared_error(y_test, y_pred_reg)\n",
        "\n",
        "# Сравнение результатов\n",
        "results = {\n",
        "    'MLP (3 hidden layers)': {'MAE': mae_3, 'MSE': mse_3},\n",
        "    'MLP (5 hidden layers)': {'MAE': mae_5, 'MSE': mse_5},\n",
        "    'MLP с регуляризацией': {'MAE': mae_reg, 'MSE': mse_reg}\n",
        "}\n",
        "\n",
        "# Вывод таблицы\n",
        "results_df = pd.DataFrame(results).T\n",
        "print(\"Сравнение моделей:\")\n",
        "print(results_df)\n",
        "\n",
        "# Лучшая модель по MAE\n",
        "best_model_name = results_df['MAE'].idxmin()\n",
        "print(f\"\\nЛучшая модель по MAE: {best_model_name}\")\n"
      ],
      "metadata": {
        "id": "RQrKbVpWlNNR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YexAXlkdyLw7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}